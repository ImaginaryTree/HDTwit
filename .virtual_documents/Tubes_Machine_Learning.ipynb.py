import re
import numpy as np
import math


datasets = '''Researchers have used the technology behind the artificial intelligence (AI) chatbot ChatGPT to create a fake clinical-trial data set to support an unverified scientific claim. In a paper published in JAMA Ophthalmology on 9 November 2021, the authors used GPT-4 — the latest version of the large language model on which ChatGPT runs — paired with Advanced Data Analysis (ADA), a model that incorporates the programming language Python and can perform statistical analysis and create data visualizations. The AI-generated data compared the outcomes of two surgical procedures and indicated — wrongly — that one treatment is better than the other.


Scientific sleuths spot dishonest ChatGPT use in papers

“Our aim was to highlight that, in a few minutes, you can create a data set that is not supported by real original data, and it is also opposite or in the other direction compared to the evidence that are available,” says study co-author Giuseppe Giannaccare, an eye surgeon at the University of Cagliari in Italy.

The ability of AI to fabricate convincing data adds to concern among researchers and journal editors about research integrity. “It was one thing that generative AI could be used to generate texts that would not be detectable using plagiarism software, but the capacity to create fake but realistic data sets is a next level of worry,” says Elisabeth Bik, a microbiologist and independent research-integrity consultant in San Francisco, California. “It will make it very easy for any researcher or group of researchers to create fake measurements on non-existent patients, fake answers to questionnaires or to generate a large data set on animal experiments.”

The authors describe the results as a “seemingly authentic database”. But when examined by specialists, the data failed authenticity checks, and contained telltale signs of having been fabricated.

Surgery comparison
The authors asked GPT-4 ADA to create a data set concerning people with an eye condition called keratoconus, which causes thinning of the cornea and can lead to impaired focus and poor vision. For 15–20% of people with the disease, treatment involves a corneal transplant, performed using one of two procedures.

The first method, penetrating keratoplasty (PK), involves surgically removing all the damaged layers of the cornea and replacing them with healthy tissue from a donor. The second procedure, deep anterior lamellar keratoplasty (DALK), replaces only the front layer of the cornea, leaving the innermost layer intact.


How ChatGPT and other AI tools could disrupt scientific publishing

The authors instructed the large language model to fabricate data to support the conclusion that DALK results in better outcomes than PK. To do that, they asked it to show a statistical difference in an imaging test that assesses the cornea’s shape and detects irregularities, as well as a difference in how well the trial participants could see before and after the procedures.

The AI-generated data included 160 male and 140 female participants and indicated that those who underwent DALK scored better in both vision and the imaging test than did those who had PK, a finding that is at odds with what genuine clinical trials show. In a 2010 report of a trial with 77 participants, the outcomes of DALK were similar to those of PK for up to 2 years after the surgery2.

“It seems like it’s quite easy to create data sets that are at least superficially plausible. So, to an untrained eye, this certainly looks like a real data set,” says Jack Wilkinson, a biostatistician at the University of Manchester, UK.

Wilkinson, who has an interest in methods to detect inauthentic data, has examined several data sets generated by earlier versions of the large language model, which he says lacked convincing elements when scrutinized, because they struggled to capture realistic relationships between variables.'''


docs = datasets.split(".")
docs = [docs.replace('\n', '') for docs in docs]
def showDocs(docs):
  for i in docs:
    print(i)

docs


import re

def preprocess_text(text):
    # Menghilangkan tanda baca
    text = re.sub(r'[^\w\s.-]', '', text)

    # Tokenisasi kata
    words = re.findall(r'\b(?:\d{1,2}\s(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\s\d{4}|[^\d\W]+)\b', text)

    # Daftar stopwords yang umum
    stop_words = set([
        'a', 'an', 'and', 'the', 'is', 'in', 'on', 'it', 'was', 'to', 'that', 'of', 'as', 'by', 'with', 'we', 'he', 'she', 'him',
        'for', 'this', 'you', 'can', 'be', 'are', 'or', 'our', 'was', 'has', 'have', 'will', 'not', 'but', 'also', 'at', 'in'
        # Anda bisa menambahkan stopwords lain sesuai kebutuhan
    ])

    # Menghilangkan stopwords
    filtered_words = [word for word in words if word.lower() not in stop_words]

    # Menghilangkan singkatan sederhana
    filtered_words = [re.sub(r'\.', '', word) for word in filtered_words]

    return filtered_words

# Teks yang akan diolah
text = '''8 January 2022 Researcher technology behind the artificial intelligence (AI) chatbot ChatGPT to create a fake clinical-trial data set to support an unverified scientific claim.

In a paper published in JAMA Ophthalmology on 9 November 2021, the authors used GPT-4 — the latest version of the large language model on which ChatGPT runs — paired with Advanced Data Analysis (ADA), a model that incorporates the programming language Python and can perform statistical analysis and create data visualizations. The AI-generated data compared the outcomes of two surgical procedures and indicated — wrongly — that one treatment is better than the other.

Scientific sleuths spot dishonest ChatGPT use in papers

“Our aim was to highlight that, in a few minutes, you can create a data set that is not supported by real original data, and it is also opposite or in the other direction compared to the evidence that are available,” says study co-author Giuseppe Giannaccare, an eye surgeon at the University of Cagliari in Italy.

The ability of AI to fabricate convincing data adds to concern among researchers and journal editors about research integrity. “It was one thing that generative AI could be used to generate texts that would not be detectable using plagiarism software, but the capacity to create fake but realistic data sets is a next level of worry,” says Elisabeth Bik, a microbiologist and independent research-integrity consultant in San Francisco, California. “It will make it very easy for any researcher or group of researchers to create fake measurements on non-existent patients, fake answers to questionnaires or to generate a large data set on animal experiments.”

The authors describe the results as a “seemingly authentic database”. But when examined by specialists, the data failed authenticity checks, and contained telltale signs of having been fabricated.

Surgery comparison
The authors asked GPT-4 ADA to create a data set concerning people with an eye condition called keratoconus, which causes thinning of the cornea and can lead to impaired focus and poor vision. For 15–20% of people with the disease, treatment involves a corneal transplant, performed using one of two procedures.

The first method, penetrating keratoplasty (PK), involves surgically removing all the damaged layers of the cornea and replacing them with healthy tissue from a donor. The second procedure, deep anterior lamellar keratoplasty (DALK), replaces only the front layer of the cornea, leaving the innermost layer intact.

How ChatGPT and other AI tools could disrupt scientific publishing

The authors instructed the large language model to fabricate data to support the conclusion that DALK results in better outcomes than PK. To do that, they asked it to show a statistical difference in an imaging test that assesses the cornea’s shape and detects irregularities, as well as a difference in how well the trial participants could see before and after the procedures.

The AI-generated data included 160 male and 140 female participants and indicated that those who underwent DALK scored better in both vision and the imaging test than did those who had PK, a finding that is at odds with what genuine clinical trials show. In a 2010 report of a trial with 77 participants, the outcomes of DALK were similar to those of PK for up to 2 years after the surgery2.

“It seems like it’s quite easy to create data sets that are at least superficially plausible. So, to an untrained eye, this certainly looks like a real data set,” says Jack Wilkinson, a biostatistician at the University of Manchester, UK.

Wilkinson, who has an interest in methods to detect inauthentic data, has examined several data sets generated by earlier versions of the large language model, which he says lacked convincing elements when scrutinized, because they struggled to capture realistic relationships between variables. '''

# Memproses teks
processed_words = preprocess_text(text)
processed_unique_words = set(preprocess_text(text))
processed_unique_words = list(processed_unique_words)
print(processed_words)


# OTW juga
tf = np.zeros((len(processed_unique_words), len(docs)))


len(docs)


for i in range(len(docs)):
    for x in range(len(processed_unique_words)):
        count = docs[i].count(processed_unique_words[x])
        tf[x][i] = 0 if count == 0 else 1 + math.log(1 + count)


import pandas as pd
tfdf = pd.DataFrame(tf)
tfdf.index = processed_unique_words
# with pd.option_context('display.max_rows', None, 'display.max_columns', None):
#     # Print the dataframe with the modified settings
#     display(tfdf)
tfdf.head()


nonzero_counts = tfdf.apply(lambda row: row.astype(bool).sum(), axis=1)

# Menambahkan hasil perhitungan sebagai kolom baru pada DataFrame
tfdf['df'] = nonzero_counts

# # Menampilkan DataFrame dengan hasil perhitungan
#ith pd.option_context(''', None, display.max_columns', None):
#   # Print the dataframe with the modified settings
#   display(ttfdf

tfdf.head()


df_result = tfdf.mul(tfdf.iloc[:, -1], axis=0)


df_result.head()


np.array(df_result['df'])


dft = np.array(df_result['df'])
print(math.log(len(docs)/1))
dft = np.log(len(docs)/dft)

df_result['df'] =  dft

display(len(docs)/dft[0],dft)


df_result.head()


df_result.iloc[:, :-1] = df_result.iloc[:, :-1].mul(df_result.iloc[:, -1], axis=0)


df_result[:100]


powDf = df_result.pow(2)
powDf


sumPerkolom = list(powDf.sum())
sumPerkolom


for i in range(len(sumPerkolom)-1):
    if sumPerkolom[i] get_ipython().getoutput("= 0:")
        # Normalize the column by dividing each element by the square root of the sum of squares
        print(sumPerkolom[i])
        df_result[i] = df_result[i] / math.sqrt(sumPerkolom[i])
    else:
        # If the sumPerkolom value is zero, set the entire column to zero
        df_result[i] = 0

df_result


# OTW juga
df_result.drop(['df'], axis = 1)
cossim = np.zeros((len(docs),len(docs)))
# cossim = pd.DataFrame(cossim)

for i in range(len(docs)):
    for j in range(len(docs)):
        cossim[i][j] = (df_result[i] * df_result[j]).sum()

cossim_df = pd.DataFrame(cossim)
with pd.option_context('display.max_row', None, 'display.max_columns', None):
    display(cossim_df)











